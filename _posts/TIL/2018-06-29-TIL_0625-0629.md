---
layout: post
title: "TIL - 0625-0629"
date: 2018-06-29 00:00:00
img:
categories:
- TIL
tags: [TIL]
---

## 0625

`프로젝트 이야기`
- 생성된 docker images에서 `redis` 를 설치하는 과정은 시간이 너무 오래걸렸다. 이 방싱보단 docker hub에서 제공하는 reids 이미지를 from 으로 설정하여설치해보자!
[ElasticCache and celery](https://darkblank.github.io/development/Elasticache/)
- redis의 경우 supervisor 를 이용하여 background 에서 실행되도록 하자
- 검색키워드로 이미지를 보내는 사람도 있었다. 이 경우 찾지 못한 키워드로 분류를 해야 할것 같다.


---

## 0626

`오늘 한 일`
- supervisord 에서 redis-server와 celery 실행
- Docker-compose의 경우 DOCKERFILE CMD에 선언되어있던 supervisord 명령어를 제대로 실행시키지 않았음 그리고 나서 docker-compose command로 넘어간것 같다.

### 프로젝트 정리 할 것들
- Dorker compose
- local 환경에서 redis, celery 연결

### Django Form validation 정리
```Console

class SignupForm(forms.Form):
    field1 (username)
    field2 (password)
    field3 (email)

form = SignupForm(request.POST) <- bound form
form.is_valid()

- 순서
Field의 메서드 x 3
    1. to_python()
    2. validate()
    3. run_validator()
        -> (1,2,3통합)Field.clean()
        -> 3개의 메서드를 정상적으로 통과하면 form.cleaned_data에 해당 Field key, value를 추가
            ex) form.cleaned_data['username'] = <입력한 값>

Form의 메서드
    1. clean_<field_name>이 해당 메서드가 존재하는 수 만큼
        -> Field의 유형이 아닌, 특정 값에 대한 유효성 검증
            ex) 입력받은 username이 중복되는 User가 있으면 ValidationError
        -> 검증에 성공하면, cleaned_data[field_name]의 값을 리턴해줌
    2. clean()
        -> 여러개의 Field값에 대해 유효성 검증이 필요할 때
            ex) password1, password2가 같은지
        -> 검증에 성공하면, cleaned_data dict가 될 객체를 반환
```

---

## 0627

`오늘 할 일`
- </s>버블 정렬 공부 (swap, 칵테일)</s>
- celery dev, production 환경에서 확인 및 배포

### 프로젝트 이야기
- celery task를 import할때 `from books.tasks import book_detail_save`이런식으로 받아오면 worker로 인식하지 못하는 문제가 있었다. 아직 원인이 뭔지 모르겠으나,`import books import tasks`이런식으로 import를 하면문제가 없었다.
- 비동기 방식이 정확하게 무엇인가 개념을 잡으면서, 현재 코드가 단지 celery를 붙였을 뿐 작동은 비동기적으로 이뤄지지 않는다는 것을 알게 되었다. 그래서 기본 문서를 다시 보면서 공부를 했다. 그 결과 사용자에게 결과를 주되, celery task로 책 상세 정보와, 위치 정보를 처리하게 했다. 시간 단축의 경우 1초정도가 차이 났다.
- local, dev, production 체크 했을 때만 해도 코드가 잘 동작했는데, 최종 배포 관련 dockerfile의 경우 uwsgi 연결이 안되는 문제가 발생했다. 그리고 최종 docker 이미지까지 확인을 했어야 했는데 성급한 배포는 결국 하루 정도 서버를 죽게 하는 결과를 가져왔다. **최종 docker 이미지까지 꼼꼼하게 체크하자**

```console
/* 바뀐 코드 */
search_book()
              > 상세 검색: search_book_detail()
              > 제목 검색: search_book_title()
                                            > 도서 검색 리스트: get_book_lists()     - requests요청
                                              - 0)도서 인스턴스 생성 book(book_id)                                             > 도서 검색 결과 출력
                                            > celery
                                              - 1)도서 상세 정보: get_book_detail(book_id) - requests요청/DB 저장
                                              - 2)도서 위치 정보: get_book_location(book_id,그외 상세)  - requests요청/DB 저장    >DB에 정보 저장

```

----

## 0628

`오늘 할 일`
- celery 적용된 부분 배포 하기

### 프로젝트 이야기
- 아침에 다시 꼼꼼하게 뭐가 엉켰는지 체크해본 결과 `requriements`에서 문제가 있었다는 것을 알게됬다. 이부분만 제대로 수정하니 금방 해결되는 문제였는데, 어제는 왜 못찾았을까? 이렇게 하여 챗봇 서비스 검색 속도도 향상되고 비동기적으로 일을 처리 할 수 있게 되었다.
- ElasticCache를 사용하지 않았는데 local redis가 잘 작동하는 걸 보고 굳이 Elasticache를 써야 하는가에 대한 의문이 생겼다.
- **celery import 부분 문제** , 비동기 관련 글 정리하기

### 프로젝트 버그
- 개인저자 , 소개 부분이 글자수 길이가 긴 경우가 있다. 이 경우 어떻게 처리를 할 것인지 체크할것
- message get, post방식으로 분리하기

----

## 0629

`오늘 할 일`
- 프로젝트 버그 수정
- <s>대나무숲 홍보글 연락하기</s>
- ElasticCache 적용하기

`주말 할 일`
- Instagram 기능 구현
    - 대댓글
    - follow, block
    - hashtag
